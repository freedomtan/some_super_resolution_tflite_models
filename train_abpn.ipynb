{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/freedomtan/some_super_resolution_tflite_models/blob/main/train_abpn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mSg2SiYLk-yn"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Conv2D, Input, ReLU, Lambda, Add\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.initializers import glorot_normal\n",
        "\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.losses import MeanAbsoluteError\n",
        "from tensorflow.keras.optimizers.schedules import PiecewiseConstantDecay\n",
        "\n",
        "import tensorflow.keras.backend as K"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load DIV2K from [TensorFlow Datasets](https://www.tensorflow.org/datasets)"
      ],
      "metadata": {
        "id": "Uw5yvKe_9Qqh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z6tyH1Ho3b3c"
      },
      "outputs": [],
      "source": [
        "import tensorflow_datasets as tfds\n",
        "ds_div2k = tfds.load('div2k', shuffle_files=True)\n",
        "\n",
        "ds_train = ds_div2k['train']\n",
        "ds_test = ds_div2k['validation']"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ABPN from the authors' [repo](https://github.com/NJU-Jet/SR_Mobile_Quantization), I fixed `upsample_in = ...`"
      ],
      "metadata": {
        "id": "c8zEH0jt91PL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VjjIR1vWmprq"
      },
      "outputs": [],
      "source": [
        "def abpn(scale=3, in_channels=3, num_fea=28, m=4, out_channels=3):\n",
        "    inp = Input(shape=(None, None, 3)) \n",
        "    upsample_func = Lambda(lambda x_list: tf.concat(x_list, axis=3))\n",
        "    upsampled_inp = upsample_func([inp for x in range(scale**2)])\n",
        "\n",
        "    # Feature extraction\n",
        "    x = Conv2D(num_fea, 3, padding='same', activation='relu', kernel_initializer=glorot_normal(), bias_initializer='zeros')(inp)\n",
        "\n",
        "    for i in range(m):\n",
        "        x = Conv2D(num_fea, 3, padding='same', activation='relu', kernel_initializer=glorot_normal(), bias_initializer='zeros')(x)\n",
        "\n",
        "    # Pixel-Shuffle\n",
        "    x = Conv2D(out_channels*(scale**2), 3, padding='same', activation='relu', kernel_initializer=glorot_normal(), bias_initializer='zeros')(x)\n",
        "    x = Conv2D(out_channels*(scale**2), 3, padding='same', kernel_initializer=glorot_normal(), bias_initializer='zeros')(x)\n",
        "    x = Add()([upsampled_inp, x])\n",
        "    \n",
        "    depth_to_space = Lambda(lambda x: tf.nn.depth_to_space(x, scale))\n",
        "    out = depth_to_space(x)\n",
        "    clip_func = Lambda(lambda x: K.clip(x, 0., 255.))\n",
        "    out = clip_func(out)\n",
        "    \n",
        "    return Model(inputs=inp, outputs=out, name='abpn')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preprocessing functions from @krasserm's super [resolution repo](https://github.com/krasserm/super-resolution)\n",
        "\n",
        "patch size for training: 96x96 (48x48 -> 96x96)\n",
        "training batch size: 64"
      ],
      "metadata": {
        "id": "Vkz5CD3R_Rsm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K5qqnKZvmsHh"
      },
      "outputs": [],
      "source": [
        "def random_crop(ds, hr_crop_size=96, scale=2):\n",
        "    lr_img = ds['lr']\n",
        "    hr_img = ds['hr']\n",
        "    \n",
        "    lr_crop_size = hr_crop_size // scale\n",
        "    lr_img_shape = tf.shape(lr_img)[:2]\n",
        "\n",
        "    lr_w = tf.random.uniform(shape=(), maxval=lr_img_shape[1] - lr_crop_size + 1, dtype=tf.int32)\n",
        "    lr_h = tf.random.uniform(shape=(), maxval=lr_img_shape[0] - lr_crop_size + 1, dtype=tf.int32)\n",
        "\n",
        "    hr_w = lr_w * scale\n",
        "    hr_h = lr_h * scale\n",
        "\n",
        "    lr_img_cropped = lr_img[lr_h:lr_h + lr_crop_size, lr_w:lr_w + lr_crop_size]\n",
        "    hr_img_cropped = hr_img[hr_h:hr_h + hr_crop_size, hr_w:hr_w + hr_crop_size]\n",
        "\n",
        "    return lr_img_cropped, hr_img_cropped\n",
        "\n",
        "def random_flip(lr_img, hr_img):\n",
        "    rn = tf.random.uniform(shape=(), maxval=1)\n",
        "    return tf.cond(rn < 0.5,\n",
        "                   lambda: (lr_img, hr_img),\n",
        "                   lambda: (tf.image.flip_left_right(lr_img),\n",
        "                            tf.image.flip_left_right(hr_img)))\n",
        "\n",
        "\n",
        "def random_rotate(lr_img, hr_img):\n",
        "    rn = tf.random.uniform(shape=(), maxval=4, dtype=tf.int32)\n",
        "    return tf.image.rot90(lr_img, rn), tf.image.rot90(hr_img, rn)\n",
        "\n",
        "from tensorflow.data import AUTOTUNE\n",
        "\n",
        "def get_patches(ds_train):\n",
        "  batch_size = 64\n",
        "  repeat_count = None\n",
        "\n",
        "  ds = ds_train.map(lambda ds: random_crop(ds), num_parallel_calls=AUTOTUNE)\n",
        "  ds = ds.map(random_rotate, num_parallel_calls=AUTOTUNE)\n",
        "  ds = ds.map(random_flip, num_parallel_calls=AUTOTUNE)\n",
        "  ds = ds.batch(batch_size)\n",
        "  ds = ds.repeat(repeat_count)\n",
        "  ds = ds.prefetch(buffer_size=AUTOTUNE)\n",
        "  return ds\n",
        "\n",
        "def wrapper(ds):\n",
        "  return ds['lr'], ds['hr']\n",
        "\n",
        "def get_part(ds_test):\n",
        "  batch_size = 1\n",
        "  repeat_count = 1\n",
        "\n",
        "  ds = ds_test.map(lambda ds: wrapper(ds), num_parallel_calls=AUTOTUNE)\n",
        "  ds = ds.batch(batch_size)\n",
        "  ds = ds.repeat(repeat_count)\n",
        "  ds = ds.prefetch(buffer_size=AUTOTUNE)\n",
        "  return ds"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = abpn(2) # ABPN super resolution scale = 2"
      ],
      "metadata": {
        "id": "jbmrrxGmNtVV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Bgda36K3sn0"
      },
      "outputs": [],
      "source": [
        "def psnr_fn(y, x):\n",
        "    psnr = tf.image.psnr(x, y, max_val = 255.0)\n",
        "    return psnr\n",
        "\n",
        "mean_psnr = tf.keras.metrics.MeanMetricWrapper(fn=psnr_fn, name='mean_psnr')\n",
        "\n",
        "learning_rate = PiecewiseConstantDecay(boundaries=[200000], values=[1e-4, 5e-5])\n",
        "model.compile(Adam(learning_rate=learning_rate),loss='mean_absolute_error', metrics = [mean_psnr])\n",
        "\n",
        "checkpoint_filepath = '/tmp/abpn/checkpoint'\n",
        "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_filepath,\n",
        "    save_weights_only=True,\n",
        "    monitor='val_mean_psnr',\n",
        "    mode='max',\n",
        "    save_best_only=True)\n",
        "\n",
        "tb_callback = tf.keras.callbacks.TensorBoard('/tmp/abpn_x2/logs', update_freq=1)\n",
        "\n",
        "ds_patches = get_patches(ds_train)\n",
        "ds_test_batched = get_part(ds_test)\n",
        "\n",
        "history = model.fit(\n",
        "    ds_patches,\n",
        "    epochs=300,\n",
        "    steps_per_epoch=1000,\n",
        "    validation_data = ds_test_batched.take(10),\n",
        "    callbacks = [model_checkpoint_callback, tb_callback]\n",
        "    )"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "test abpn.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}